{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test GPU:  True\n",
      "Test CUDA:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time \n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions:\n",
    "    1. Normalize the data ...\n",
    "\"\"\"\n",
    "\n",
    "def normalize(X_train, X_test):\n",
    "    \n",
    "    X_all = X_train\n",
    "    mean = np.mean(X_all, axis=0)\n",
    "    std = np.std(X_all, axis=0)\n",
    "\n",
    "    index = [0, 1, 3, 4, 5]\n",
    "    mean_vec = np.zeros(X_all.shape[1])\n",
    "    std_vec = np.ones(X_all.shape[1])\n",
    "    mean_vec[index] = mean[index]\n",
    "    std_vec[index] = std[index]\n",
    "\n",
    "    X_all_std = (X_all - mean_vec) / std_vec\n",
    "    X_train_std = X_all_std[0:X_train.shape[0]]\n",
    "    X_test_std = X_all_std[X_train.shape[0]:]\n",
    "\n",
    "    return X_train_std, X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 106)\n",
      "(32561, 1)\n",
      "(32561, 106)\n",
      "(32561, 1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    1. Load csv file (UCI Census Income Dataset) \n",
    "    2. Trans df into numpy\n",
    "    3. Normalize the data\n",
    "    4. Spilt Train & Test Data\n",
    "--- \n",
    "    Actually, I do lots of data preprocessing cause' I find the data sizes are imbalanced. Therefore,\n",
    "    I use the imblearn package(Oversampling, undersampling, or combination). However, I couldn't get better score\n",
    "    with these methods on Kaggle. Maybe, there are some problem in these datasets.(Sparse Data Point or something\n",
    "    others...)\n",
    "---\n",
    "\n",
    "'''\n",
    "\n",
    "X_train = pd.read_csv('./X_train')\n",
    "y_train = pd.read_csv('./Y_train', header=None)\n",
    "X_test = pd.read_csv('./X_test')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train_std, X_test_std = normalize(X_train, X_test)\n",
    "\n",
    "X_all_std = X_train_std\n",
    "y_all = y_train\n",
    "\n",
    "X_train_std, X_val_std, y_train, y_val = train_test_split(X_train_std, y_train, test_size=0.33, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Hyperparams Tuning ... \n",
    "    * We can find best train loss in this method. However, it will cost lots of time.(Exec on CPU)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.2,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.1], 'n_estimators': [400, 500, 600, 700, 800, 900], 'max_depth': [3, 4, 5, 6], 'subsample': [0.85, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = GradientBoostingClassifier(loss = 'deviance', validation_fraction=0.2)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [400, 500, 600, 700, 800, 900],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'subsample': [0.85, 0.9]\n",
    "}\n",
    "\n",
    "gbc = GridSearchCV(estimator, param_grid, cv=5, n_jobs=-1)\n",
    "gbc.fit(X_all_std, y_all)\n",
    "\n",
    "# Best parameters found by grid search are: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'random_state': 2025}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.8724240655999509\n",
      "[0.87214766 0.87147201 0.87162556 0.87227051 0.87153343 0.87242407\n",
      " 0.87190197 0.8719941  0.87131845 0.87150272 0.87082706 0.87107276\n",
      " 0.87193268 0.87205553 0.8709192  0.87165628 0.87104204 0.87104204\n",
      " 0.8695986  0.86999785 0.86938362 0.8703971  0.86790946 0.86855441\n",
      " 0.86999785 0.87104204 0.86993643 0.86947575 0.8690765  0.86797089\n",
      " 0.866681   0.86763306 0.86575965 0.86643531 0.86419336 0.86560609\n",
      " 0.86692669 0.86953718 0.86572894 0.86646602 0.86631246 0.86575965\n",
      " 0.86496115 0.86468475 0.86370197 0.86459261 0.86265778 0.86339486]\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found by grid search are:', gbc.best_params_)\n",
    "print(gbc.best_score_)\n",
    "print(gbc.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Train the classifier with the hyperparams(which found by the best score)\n",
    "    - sklearn.GradientBoostingClassifier\n",
    "    - lightLGB \n",
    "        * This GBM will get the highest score and we can exec this GBM over the GPU !\n",
    "        * In kaggle - public - 87.79XXX, private - 87.4XXXX\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888701206965388\n",
      "0.8727005495718071\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'loss': 'deviance',\n",
    "    'learning_rate': 0.1, \n",
    "    'max_depth': 5, \n",
    "    'n_estimators': 200, \n",
    "    'random_state': 2025\n",
    "}\n",
    "## 32561 - 7841 \n",
    "# clf = GradientBoostingClassifier(loss='deviance', n_estimators=500 , max_depth=5, random_state=2019,\n",
    "#                                  learning_rate=0.1, subsample=1, max_features=40)\n",
    "### csv - 27 0.876\n",
    "# clf = GradientBoostingClassifier(loss='deviance', n_estimators=300 , max_depth=4, random_state=2019, learning_rate=0.1,\n",
    "#                                 validation_fraction=0.2, tol=0.01)\n",
    "### csv - 28 = csv 12 \n",
    "# clf = GradientBoostingClassifier(loss='deviance', n_estimators=250 , max_depth=4, random_state=2019, learning_rate=0.1,\n",
    "#                                 validation_fraction=0.2, tol=0.01)\n",
    "\n",
    "### csv - 29\n",
    "# clf = GradientBoostingClassifier(loss='deviance', n_estimators=275 , max_depth=4, random_state=2019, learning_rate=0.1,\n",
    "#                                 validation_fraction=0.2, tol=0.01)\n",
    "\n",
    "### csv - 30\n",
    "clf = GradientBoostingClassifier(loss='deviance', n_estimators=300 , max_depth=4, random_state=2019, learning_rate=0.1,\n",
    "                                validation_fraction=0.2, tol=0.005)\n",
    "# clf = GradientBoostingClassifier(params)\n",
    "clf.fit(X_all_std, y_all)\n",
    "scores = cross_val_score(clf, X_all_std, y_all, cv=5)\n",
    "print(clf.score(X_all_std, y_all))\n",
    "print(np.mean(scores))\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "y_submit = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "y_submit.label = y_pred.astype(int)\n",
    "y_submit.to_csv('./submission_GBC_Test30.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smog70151/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.05, max_bin=200,\n",
       "       max_depth=4, min_child_samples=20, min_child_weight=0.001,\n",
       "       min_split_gain=0.0, n_estimators=500, n_jobs=-1, num_leaves=300,\n",
       "       objective='binary', random_state=None, reg_alpha=0.0,\n",
       "       reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# param = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate': 0.05,'max_bin':200, 'n_estimators': 100}\n",
    "# clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=300, objective='binary', learning_rate=0.05, max_bin=200\n",
    "#                        , max_depth=4, n_estimators=500)\n",
    "clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=300, objective='binary', learning_rate=0.05, max_bin=200\n",
    "                       , max_depth=4, n_estimators=500)\n",
    "clf.fit(X_all_std, y_all, eval_metric=['auc', 'binary_logloss'])\n",
    "y_pred = clf.predict(X_test_std)\n",
    "y_submit = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "y_pred = np.around(y_pred)\n",
    "y_submit.label = y_pred.astype(int)\n",
    "y_submit.to_csv('./submission_LGB_Test2.csv', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
